{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d2a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2000...\n",
      "Saved 2 rows for 2000.\n",
      "Processing 2001...\n",
      "Saved 0 rows for 2001.\n",
      "Processing 2002...\n",
      "Saved 0 rows for 2002.\n",
      "Processing 2003...\n",
      "Saved 6 rows for 2003.\n",
      "Processing 2004...\n",
      "Saved 4 rows for 2004.\n",
      "Processing 2005...\n",
      "Saved 1 rows for 2005.\n",
      "Processing 2006...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1v/1v9gr7c15vl6g0hp34mrbhkm0000gn/T/ipykernel_33432/2208577121.py:7: DtypeWarning: Columns (29,34,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'Data/Storm Event Data/{year}_storm_events.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 0 rows for 2006.\n",
      "Processing 2007...\n",
      "Saved 1 rows for 2007.\n",
      "Processing 2008...\n",
      "Saved 5 rows for 2008.\n",
      "Processing 2009...\n",
      "Saved 2 rows for 2009.\n",
      "Processing 2010...\n",
      "Saved 2 rows for 2010.\n",
      "Processing 2011...\n",
      "Saved 0 rows for 2011.\n",
      "Processing 2012...\n",
      "Saved 0 rows for 2012.\n",
      "Processing 2013...\n",
      "Saved 6 rows for 2013.\n",
      "Processing 2014...\n",
      "Saved 1 rows for 2014.\n",
      "Processing 2015...\n",
      "Saved 2 rows for 2015.\n",
      "Processing 2016...\n",
      "Saved 3 rows for 2016.\n",
      "Processing 2017...\n",
      "Saved 0 rows for 2017.\n",
      "Processing 2018...\n",
      "Saved 4 rows for 2018.\n",
      "Processing 2019...\n",
      "Saved 5 rows for 2019.\n",
      "Processing 2020...\n",
      "Saved 0 rows for 2020.\n",
      "Processing 2021...\n",
      "Saved 3 rows for 2021.\n"
     ]
    }
   ],
   "source": [
    "#cleaning storm data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "for year in range(2000, 2022):\n",
    "    print(f\"Processing {year}...\")\n",
    "    \n",
    "    # Load each years CSV\n",
    "    df = pd.read_csv(f'Data/Storm Event Data/{year}_storm_events.csv')\n",
    "    \n",
    "    # Filter for Oklahoma tornado events\n",
    "    df_ok_tornado = df[\n",
    "        (df['STATE'] == 'OKLAHOMA') &\n",
    "        (df['CZ_NAME'] == 'OKLAHOMA') &\n",
    "        (df['EVENT_TYPE'] == 'Tornado')\n",
    "    ]\n",
    "    \n",
    "    # Save filtered dataa for that year\n",
    "    df_ok_tornado.to_csv(f'Data/Storm Event Data/{year}_oklahoma_tornadoes.csv', index=False)\n",
    "    \n",
    "    print(f\"Saved {len(df_ok_tornado)} rows for {year}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2131921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Data/Storm Event Data/2005_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2002_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2008_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2001_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2006_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2007_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2000_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2009_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2003_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2004_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2016_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2011_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2020_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2018_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2012_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2015_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2014_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2013_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2019_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2021_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2010_oklahoma_tornadoes.csv ...\n",
      "Adding Data/Storm Event Data/2017_oklahoma_tornadoes.csv ...\n",
      "✅ Combined file saved as Data/Storm Event Data/oklahoma_tornadoes_2000_2021.csv\n",
      "Total rows combined: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1v/1v9gr7c15vl6g0hp34mrbhkm0000gn/T/ipykernel_33432/182247574.py:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all = pd.concat(dfs, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#put it all together\n",
    "import glob\n",
    "\n",
    "\n",
    "files = glob.glob('Data/Storm Event Data/*_oklahoma_tornadoes.csv')\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Adding {file} ...\")\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Combine them all\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save to a single CSV\n",
    "output_path = 'Data/Storm Event Data/oklahoma_tornadoes_2000_2021.csv'\n",
    "df_all.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Combined file saved as {output_path}\")\n",
    "print(f\"Total rows combined: {len(df_all)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbc700",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CLEANING OKC Station\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fab69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
